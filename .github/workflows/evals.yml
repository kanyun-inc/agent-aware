name: Evals

on:
  pull_request:
    branches:
      - main
  push:
    branches:
      - main
  workflow_dispatch: # æ”¯æŒæ‰‹åŠ¨è§¦å‘

jobs:
  eval:
    name: Run Evaluations
    runs-on: ubuntu-latest
    permissions:
      contents: read
      pull-requests: write
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Install pnpm
        uses: pnpm/action-setup@v4
        with:
          version: 9

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20.x'
          cache: 'pnpm'

      - name: Install dependencies
        run: pnpm install --frozen-lockfile

      - name: Build
        run: pnpm build

      - name: Run Evaluations
        id: eval
        run: |
          pnpm eval --trials 5 --parallel 2>&1 | tee eval-output.txt
          exit_code=${PIPESTATUS[0]}
          echo "exit_code=$exit_code" >> $GITHUB_OUTPUT
        continue-on-error: true

      - name: Generate Summary
        run: |
          # è¯»å–æœ€æ–°çš„ Markdown æŠ¥å‘Š
          REPORT_FILE=$(ls -t evals/results/*.md 2>/dev/null | head -1)
          
          if [ -f "$REPORT_FILE" ]; then
            echo "## ðŸ“Š Agent-aware è¯„ä¼°æŠ¥å‘Š" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            cat "$REPORT_FILE" | tail -n +2 >> $GITHUB_STEP_SUMMARY
          else
            echo "## âŒ è¯„ä¼°æŠ¥å‘Šç”Ÿæˆå¤±è´¥" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "è¯·æ£€æŸ¥è¯„ä¼°æ—¥å¿—èŽ·å–è¯¦ç»†ä¿¡æ¯ã€‚" >> $GITHUB_STEP_SUMMARY
          fi

      - name: Comment on PR
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const path = require('path');
            
            // æŸ¥æ‰¾æœ€æ–°çš„ Markdown æŠ¥å‘Š
            const resultsDir = 'evals/results';
            let reportContent = '';
            
            try {
              const files = fs.readdirSync(resultsDir)
                .filter(f => f.endsWith('.md'))
                .sort()
                .reverse();
              
              if (files.length > 0) {
                const reportPath = path.join(resultsDir, files[0]);
                reportContent = fs.readFileSync(reportPath, 'utf8');
              }
            } catch (e) {
              console.log('No report file found:', e.message);
            }
            
            // æž„å»ºè¯„è®ºå†…å®¹
            let body = '## ðŸ“Š Agent-aware è¯„ä¼°ç»“æžœ\n\n';
            
            if (reportContent) {
              // ç§»é™¤æ ‡é¢˜ï¼ˆç¬¬ä¸€è¡Œï¼‰
              const lines = reportContent.split('\n');
              body += lines.slice(1).join('\n');
            } else {
              body += 'âš ï¸ è¯„ä¼°æŠ¥å‘Šç”Ÿæˆå¤±è´¥ï¼Œè¯·æ£€æŸ¥ Actions æ—¥å¿—ã€‚\n';
            }
            
            body += '\n\n---\n';
            body += `*Generated by [Agent-aware Evals](${process.env.GITHUB_SERVER_URL}/${process.env.GITHUB_REPOSITORY}/actions/runs/${process.env.GITHUB_RUN_ID})*`;
            
            // æŸ¥æ‰¾å¹¶æ›´æ–°æˆ–åˆ›å»ºè¯„è®º
            const { data: comments } = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
            });
            
            const botComment = comments.find(c => 
              c.user.type === 'Bot' && 
              c.body.includes('Agent-aware è¯„ä¼°ç»“æžœ')
            );
            
            if (botComment) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: botComment.id,
                body: body,
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: body,
              });
            }

      - name: Upload Eval Results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: eval-results
          path: |
            evals/results/*.json
            evals/results/*.md
            evals/results/transcripts/
          retention-days: 30

      - name: Check Eval Status
        if: steps.eval.outputs.exit_code != '0'
        run: |
          echo "::error::è¯„ä¼°æœªå…¨éƒ¨é€šè¿‡ï¼Œè¯·æ£€æŸ¥æŠ¥å‘Šè¯¦æƒ…"
          exit 1
